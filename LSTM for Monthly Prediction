#Preprocessing the data to fit in lstm model
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Load the preprocessed data
file_path = 'C:/Users/nanda/Downloads/final_data.csv'
dataset = pd.read_csv(file_path)

# Convert 'Transaction Time' to datetime and preprocess as before

dataset['Datetime'] = pd.to_datetime(dataset['Transaction Time'], errors='coerce')
dataset = dataset[dataset['Datetime'] >= '2024-01-01']
dataset = dataset[dataset['Fare Product'] != 'Staff Card']
dataset['Date'] = dataset['Datetime'].dt.date
dataset['hour'] = dataset['Datetime'].dt.floor('h')
hourly_passenger_flow = dataset.groupby(['hour', 'Station', 'Date']).size().reset_index(name='Passenger Flow')
pivot_data = hourly_passenger_flow.pivot(index='hour', columns='Station', values='Passenger Flow').fillna(0)

# Normalize the data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(pivot_data)

# Create sequences for LSTM input
sequence_length = 24  # Number of hours to look back
X, y = [], []
for i in range(sequence_length, len(scaled_data)):
    X.append(scaled_data[i-sequence_length:i])
    y.append(scaled_data[i])

X, y = np.array(X), np.array(y)

# Display the shapes of the input and output
print(f'Input shape: {X.shape}, Output shape: {y.shape}')

#Training the model

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Load the preprocessed data
file_path = 'C:/Users/nanda/Downloads/merged_csv_2.csv'
dataset = pd.read_csv(file_path)

# Convert 'Transaction Time' to datetime and preprocess as before

dataset['Datetime'] = pd.to_datetime(dataset['Transaction Time'], errors='coerce')
dataset = dataset[dataset['Datetime'] >= '2024-01-01']
dataset = dataset[dataset['Fare Product'] != 'Staff Card']
dataset['Date'] = dataset['Datetime'].dt.date
dataset['hour'] = dataset['Datetime'].dt.floor('h')
hourly_passenger_flow = dataset.groupby(['hour', 'Station', 'Date']).size().reset_index(name='Passenger Flow')
pivot_data = hourly_passenger_flow.pivot(index='hour', columns='Station', values='Passenger Flow').fillna(0)

# Normalize the data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(pivot_data)

# Create sequences for LSTM input
sequence_length = 24  # Number of hours to look back
X, y = [], []
for i in range(sequence_length, len(scaled_data)):
    X.append(scaled_data[i-sequence_length:i])
    y.append(scaled_data[i])

X, y = np.array(X), np.array(y)

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(y.shape[1]))
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X, y, epochs=50, batch_size=32)

# Save the model
model.save('passenger_flow_lstm_model.h5')

print('Model training complete and saved.')
